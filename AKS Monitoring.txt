AKS Monitioring alerts
------------
Background:
To monitor the performance of containers in an AKS cluster, we can create alerts which would notify users of certain issues pertaining to the performance of an AKS cluster. 
For example, we can create an alert which sends out an email to specific users if there are multiple failed containers or if CPU or memory usage exceeds some threshold value.

Workspace creation
Before creating alerts, we need to have a Log analytics workspace, a service of Azure which enables us to collect data from various sources like virtual machines, 
kubernetes services, SQL databases etc. While creation of a Log Analytics workspace, 
we need to specify the subscription and resource group of the target AKS cluster you would like to create alerts for.

Once workspace gets created, to do monitoring of cluster we need to enable monitoring add-on for the AKS cluster using following Azure CLI command:

az aks enable-addons -a monitoring -n MyExistingManagedCluster -g MyExistingManagedClusterRG

This will make all tables related to Kubernetes monitoring available to be queried under ContainerInsights category. 
For example, KubeEvents table has data related to Kubernetes Events, ContainerLog table has all the logs generated by the containers. 
These tables can be queried to check for any performance related issues. For example, we can query KubeEvent table to check if there are any failed container.
------------
Creating new alert rule
Once we have a workspace created, we can proceed to create performance related alert rules. Log analytics workspace provides Log Analytics Query language which can be used to query the tables. This query language is similar to SQL with additional capability to render charts.

Create an Alert

Go-to Logs of the workspace
Enter the query in the space provided to run a query (Queries are listed below)
Click on + New alert rule, scope is pre-selected based on the workspace
Specify the condition by configuring the signal logic by clicking on the condition name
Select Number of results, in Operator select greater than, in Threshold value select 0 (example, for failed container query, it means if the number of failed containers returned by the query is greater than 0, trigger the alert)
In Evaluated based on, select the time span over which you want your query to be executed
In Frequency, select the query execution frequency
Click on Done.
Select action group. Action Group is where you specify type of action you want to perform when the alert is triggered, for example, you can send out an email or an SMS to specific people responsible for performance monitoring. If there are no action group present, you can create a new one.
In Customize option, you can specify Email subject.
Enter Alert rule details like, name, description, severity etc.
Once done, click on Create alert rule.
Following are the basic performance related queries:

Failed Containers: 
This alert rule will notify a user regarding one or more failed containers in a particular AKS. Following is the query:

KubePodInventory
| project Name, PodStatus, ContainerStatus, ContainerRestartCount
| where (ContainerStatus =~ "waiting" and ContainerRestartCount > 0) or PodStatus =~ "Failed"
| distinct Name, PodStatus, ContainerStatus
Billable Container volume by log source and namespace: 
Lists billable ContainerLog volume by logsource and namespace if cluster is ingesting more than 4 GB per hour. Following is the query:

let startTime = ago(1h);
let containerLogs = ContainerLog
| where TimeGenerated > startTime
| where _IsBillable == true
| summarize BillableDataMBytes = sum(_BilledSize)/ (1000. * 1000.) by LogEntrySource, ContainerID;
let kpi = KubePodInventory
| where TimeGenerated > startTime
| distinct ContainerID, Namespace;
containerLogs
| join kpi on $left.ContainerID == $right.ContainerID
| extend sourceNamespace = strcat(LogEntrySource, "/", Namespace)
| summarize MB=sum(BillableDataMBytes) by sourceNamespace
| where MB > 4096

Maximum node disk: 
This alert rule triggers alert if Max node disk usage average exceeds 90% thrice over 30 mins intervals. Following is the query:

// Maximum node disk
// Max node disk usage averaged over 30 mins intervals.
//InsightMetrics contains all the custom metrics for Container Insights solution
InsightsMetrics // Replace Name with your custom metric
| where Name == "used_percent" and Namespace == "container.azm.ms/disk"
| summarize val= max(Val) by bin(TimeGenerated, 15m)
| where val >= 90

Kubernetes Events: 
This Alert rule is triggered if Events of type Warning is generated with reasons such as Failed, BackOff etc. Following is the query:

// Kubernetes events
// Lists all the Kubernetes events.
KubeEvents
| where TimeGenerated > ago(7d)
| where not(isempty(Namespace))
| where KubeEventType == "Warning"
| distinct Name, Reason, Namespace, KubeEventType
Nodes Readiness count: 
For all your cluster view count of all the nodes by readiness(only not ready counts). Following is the query:

// Readiness status per Node
// For all your cluster view count of all the nodes by readiness.
//Customize startDateTime, endDateTime to select custom time range
let endDateTime = now();
let startDateTime = ago(1h);
let trendBinSize = 1m;
KubeNodeInventory
| where TimeGenerated < endDateTime
| where TimeGenerated >= startDateTime
| distinct ClusterName, Computer, TimeGenerated
| summarize ClusterSnapshotCount = count() by bin(TimeGenerated, trendBinSize), ClusterName, Computer
| join hint.strategy=broadcast kind=inner (
KubeNodeInventory //this calculating ready node count.
| where TimeGenerated < endDateTime
| where TimeGenerated >= startDateTime
| summarize TotalCount = count(), ReadyCount = sumif(1, Status contains ('Ready'))
by ClusterName, Computer, bin(TimeGenerated, trendBinSize) //calculating NotReadyCount
| extend NotReadyCount = TotalCount - ReadyCount
) on ClusterName, Computer, TimeGenerated
//projecting all the fields
| project TimeGenerated, ClusterName, Computer, ReadyCount = todouble(ReadyCount) / ClusterSnapshotCount,
NotReadyCount = todouble(NotReadyCount) / ClusterSnapshotCount
| where NotReadyCount > 0
| order by ClusterName asc, Computer asc, TimeGenerated desc

Avg Node memory usage: 
This alert rule triggers alert if for your cluster view avg node memory usage percentage per minute over the last hour exceeds 90%. Following is the query:

// Avg node memory usage percentage per minute
// For your cluster view avg node memory usage percentage per minute over the last hour.
let endDateTime = now();
let startDateTime = ago(1h);
let trendBinSize = 1m;
let capacityCounterName = 'memoryCapacityBytes';
let usageCounterName = 'memoryRssBytes';
KubeNodeInventory
| where TimeGenerated < endDateTime
| where TimeGenerated >= startDateTime
// cluster filter would go here if multiple clusters are reporting to the same Log Analytics workspace
| distinct ClusterName, Computer
| join hint.strategy=shuffle (
Perf
| where TimeGenerated < endDateTime
| where TimeGenerated >= startDateTime
| where ObjectName == 'K8SNode'
| where CounterName == capacityCounterName
| summarize LimitValue = max(CounterValue) by Computer, CounterName, bin(TimeGenerated, trendBinSize)
| project Computer, CapacityStartTime = TimeGenerated, CapacityEndTime = TimeGenerated + trendBinSize, LimitValue
) on Computer
| join kind=inner hint.strategy=shuffle (
Perf
| where TimeGenerated < endDateTime + trendBinSize
| where TimeGenerated >= startDateTime - trendBinSize
| where ObjectName == 'K8SNode'
| where CounterName == usageCounterName
| project Computer, UsageValue = CounterValue, TimeGenerated
) on Computer
| where TimeGenerated >= CapacityStartTime and TimeGenerated < CapacityEndTime
| project ClusterName, Computer, TimeGenerated, UsagePercent = UsageValue * 100.0 / LimitValue
| summarize AggregatedValue = avg(UsagePercent) by bin(TimeGenerated, trendBinSize), ClusterName
|where AggregatedValue >= 90
Pod Restart Count > 100

Alert rule triggers alert if pods restart > 100 times
let startTimestamp = ago(5m);
KubePodInventory
| where ClusterName =~ "cluster name"
| where ContainerRestartCount > 100
Avg Node CPU usage: 
Alert rule triggers alert if for your cluster view avg node CPU usage percentage per minute over the last hour exceeds 90%. Following is the query:

// Avg node CPU usage percentage per minute
// For your cluster view avg node CPU usage percentage per minute over the last hour.
//Modify the startDateTime & endDateTime to customize the timerange
let endDateTime = now();
let startDateTime = ago(30d);
let trendBinSize = 1m;
let capacityCounterName = 'cpuCapacityNanoCores';
let usageCounterName = 'cpuUsageNanoCores';
KubeNodeInventory
| where TimeGenerated < endDateTime
| where TimeGenerated >= startDateTime
// cluster filter would go here if multiple clusters are reporting to the same Log Analytics workspace
| distinct ClusterName, Computer
| join hint.strategy=shuffle (
Perf
| where TimeGenerated < endDateTime
| where TimeGenerated >= startDateTime
| where ObjectName == 'K8SNode'
| where CounterName == capacityCounterName
| summarize LimitValue = max(CounterValue) by Computer, CounterName, bin(TimeGenerated, trendBinSize)
| project Computer, CapacityStartTime = TimeGenerated, CapacityEndTime = TimeGenerated + trendBinSize, LimitValue
) on Computer
| join kind=inner hint.strategy=shuffle (
Perf
| where TimeGenerated < endDateTime + trendBinSize
| where TimeGenerated >= startDateTime - trendBinSize
| where ObjectName == 'K8SNode'
| where CounterName == usageCounterName
| project Computer, UsageValue = CounterValue, TimeGenerated
) on Computer
| where TimeGenerated >= CapacityStartTime and TimeGenerated < CapacityEndTime
| project ClusterName, Computer, TimeGenerated, UsagePercent = UsageValue * 100.0 / LimitValue
| summarize AggregatedValue = avg(UsagePercent) by bin(TimeGenerated, trendBinSize), ClusterName
| where AggregatedValue >= 90
